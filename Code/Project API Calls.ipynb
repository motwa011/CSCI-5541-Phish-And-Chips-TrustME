{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVItyBgHsOL84fslhRJ6gs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lETYZFKDtABR"},"outputs":[],"source":["!pip install requests\n","!pip install spacy\n","!pip install SPARQLWrapper\n","!python -m spacy download en_core_web_sm"]},{"cell_type":"code","source":["import requests\n","import spacy\n","import re\n","from SPARQLWrapper import SPARQLWrapper, JSON\n","import requests\n","import json\n","import SPARQLWrapper\n","from sentence_preprocessing import *\n","import time\n","from itertools import combinations"],"metadata":{"id":"D67FvZGZtliY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.load('en_core_web_sm')\n","\n","def sentence_preprocessing(sentence):\n","    doc = nlp(sentence)\n","\n","    # Lemmatization\n","    lemmatized_words = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n","\n","    named_entities = {ent.text: ent.label_ for ent in doc.ents}\n","\n","    keywords = [token.text for token in doc if token.pos_ in {\"NOUN\", \"VERB\", \"PROPN\"} and not token.is_stop]\n","\n","    return {\n","        \"lemmatized_words\": lemmatized_words,\n","        \"named_entities\": named_entities,\n","        \"keywords\": keywords\n","    }"],"metadata":{"id":"8LBgFxOgto_d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ConceptNet API\n","def query_conceptnet_api(term):\n","    obj = {}\n","    url = f'http://api.conceptnet.io/c/en/{term}'\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        obj = json.loads(response.text)\n","        return obj\n","    return obj\n","\n","# Wikidata API\n","def query_wikidata_api(term):\n","    sparql = SPARQLWrapper.SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n","    sparql.setQuery(f\"\"\"\n","        SELECT ?item ?itemLabel ?itemDescription\n","        WHERE\n","        {{\n","            ?item rdfs:label \"{term}\"@en.\n","            SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n","        }}\n","    \"\"\")\n","    sparql.setReturnFormat(SPARQLWrapper.JSON)\n","    results = sparql.query().convert()\n","    return results\n","\n","# DBpedia API\n","def query_dbpedia_api(terms):\n","    # Pair terms with each other with combinations\n","    # for entity1, entity2 in combinations(terms, 2):\n","    # Check if two entities have a relationship with each other\n","    sparql = SPARQLWrapper.SPARQLWrapper(\"http://dbpedia.org/sparql\")\n","    results = []\n","    # sparql.setQuery(f\"\"\"\n","    #     SELECT ? WHERE {{\n","    #         dbr:{term} dbo:abstract ?abstract.\n","    #         FILTER (lang(?abstract) = 'en')\n","    #     }}\n","    #     LIMIT 1\n","    # \"\"\")\n","    # terms is a list of keywords\n","    # sparql.setQuery(f\"\"\"\n","    # SELECT ?relation ?relatedEntity WHERE {{\n","    #     dbr:{term} ?relation ?relatedEntity.\n","    #     ?entity1 rdfs:label \"{entity1}\"@en.\n","    #     ?entity2 rdfs:label \"{entity2}\"@en.\n","    # }}\n","    # LIMIT 10\n","    # \"\"\")\n","    for term in terms:\n","        cleaned_term = term.replace(\" \", \"_\")\n","        sparql.setQuery(f\"\"\"\n","            SELECT ?relation ?relatedEntity WHERE {{\n","            dbr:{cleaned_term} ?relation ?relatedEntity.\n","            FILTER (lang(?relatedEntity) = 'en')\n","        }}\n","        LIMIT 10\n","        \"\"\")\n","        sparql.setReturnFormat(SPARQLWrapper.JSON)\n","        try:\n","            query_results = sparql.query().convert()\n","            bindings = query_results.get('results', {}).get('bindings', [])\n","            if bindings:\n","                results.append({term: bindings})\n","            else:\n","                print(f'No results found for {term}')\n","                results.append({term: []})\n","        except Exception as e:\n","            print(f'Error querying DBpedia for {term}: {e}')\n","            results.append({term: []})\n","    return results\n","\n","# Google Knowledge Graph API\n","# current API key\n","# AIzaSyCubAMJlTcNAgRiZzSMt8S8RcqtYOwgjnI\n","def query_google_knowledge_graph_api(term, api_key):\n","    url = \"https://kgsearch.googleapis.com/v1/entities:search\"\n","    params = {\n","        \"query\": term,\n","        \"limit\": 1,\n","        \"indent\": True,\n","        \"key\": api_key\n","    }\n","    response = requests.get(url, params=params)\n","    if response.status_code == 200:\n","        return json.loads(response.text)\n","    else:\n","        return {}\n","\n","# Semantic Scholar API\n","def query_semantic_scholar_api(term):\n","    url = 'https://api.semanticscholar.org/v1/paper/search'\n","    params = {\n","        'query': term,\n","        'fields': 'title,abstract,authors,year,doi,url'\n","    }\n","    response = requests.get(url, params=params)\n","    if response.status_code == 200:\n","        return json.loads(response.text)\n","    else:\n","        return {}\n","\n","def query_knowledge_base(sentence):\n","    start_time = time.time()\n","    # Process the sentence\n","    processed_sentence = sentence_preprocessing(sentence)\n","\n","    # Extract parts\n","    lemmatized_words = processed_sentence['lemmatized_words']\n","    named_entities = processed_sentence['named_entities']\n","    keywords = processed_sentence['keywords']\n","    print(f'lemmatized_words: {lemmatized_words}')\n","    print(f'named_entities: {named_entities}')\n","    print(f'keywords: {keywords}')\n","\n","    print(f\"Time taken for preprocessing: {time.time() - start_time} seconds\")\n","\n","    # # Query each API\n","    # conceptnet_results = [query_conceptnet_api(term) for term in named_entities.keys()]\n","    # # conceptnet_results = parse_conceptNet_response(conceptnet_results)\n","    # wikidata_results = [query_wikidata_api(term) for term in named_entities.keys()]\n","    # wikidata_results = parse_wikidata_response(wikidata_results)\n","    dbpedia_results = [query_dbpedia_api([item for item in named_entities.keys()])]\n","    dbpedia_results = dbpedia_results[0][0]['Albert Einstein'][1]['relatedEntity']['value']\n","    vals = []\n","    for word in named_entities.keys():\n","        if word.lower() in dbpedia_results.lower():\n","            vals.append(f'{word}: True')\n","        else:\n","            vals.append(f'{word}: False')\n","    print(vals)\n","\n","    # dbpedia_results = parse_dbpedia_response(dbpedia_results)\n","    # google_knowledge_graph_results = [query_google_knowledge_graph_api(sentence, \"AIzaSyCubAMJlTcNAgRiZzSMt8S8RcqtYOwgjnI\") for term in named_entities.keys()]\n","    # # google_knowledge_graph_results = parse_google_knowledge_graph_response(google_knowledge_graph_results)\n","    # semantic_scholar_results = [query_semantic_scholar_api(term) for term in keywords]\n","    # # semantic_scholar_results = parse_semantic_scholar_response(semantic_scholar_results)\n","\n","    print(f\"Time taken for querying APIs: {time.time() - start_time} seconds\")\n","\n","    return {\n","        # \"conceptnet\": conceptnet_results,\n","        # \"wikidata\": wikidata_results,\n","        \"dbpedia\": dbpedia_results #,\n","        # \"google_knowledge_graph\": google_knowledge_graph_results,\n","        # \"semantic_scholar\": semantic_scholar_results\n","    }\n","\n","def main():\n","    sentence = \"Albert Einstein developed the Theory of Relativity in 1905\"\n","    results = query_knowledge_base(sentence)\n","    for key, value in results.items():\n","        print(f\"Results from {key}: {value}\")\n","        print()\n","        print()\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"IEXOA5gwC1Cs"},"execution_count":null,"outputs":[]}]}